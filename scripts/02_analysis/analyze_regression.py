# -*- coding: utf-8 -*-

import pandas as pd
import numpy as np
import statsmodels.api as sm
from scipy.stats import pearsonr
import os
import matplotlib.pyplot as plt
import seaborn as sns

# --- ë°ì´í„° ê²½ë¡œ ì„¤ì • (ë¡œì»¬ íŒŒì¼ ê¸°ì¤€) ---
# NOTE: ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ëª¨ë“  CSV íŒŒì¼ì´ ë¡œì»¬ ë””ìŠ¤í¬ì— ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
AIR_QUALITY_CSV = "/data/training/national_monthly_avg.csv"  # ì´ì „ì— Sparkë¡œ ìƒì„±ëœ ì „êµ­ ì›”í‰ê·  ë°ì´í„°
POWER_DATA_CSV = "/data/training/data/raw/kepco_thermal_power_monthly.csv" # í™”ë ¥ë°œì „ ì›ë³¸ ë°ì´í„° (ê¹ƒí—ˆë¸Œ ê²½ë¡œ)

# --- ì¶œë ¥ ê²½ë¡œ ì„¤ì • ---
OUTPUT_DIR = "/data/training/analysis_results_pandas"
OUTPUT_LOCAL_SUMMARY = os.path.join(OUTPUT_DIR, "regression_summary_PM10.txt")
OUTPUT_LOCAL_HEATMAP = os.path.join(OUTPUT_DIR, "correlation_heatmap_pandas.png")

# --- ë¶„ì„ ëŒ€ìƒ ì»¬ëŸ¼ ì„¤ì • ---
TARGET_POLLUTANT = 'national_avg_PM10'
OPTIMAL_LAG = 1 # Lagged Correlationì—ì„œ ë„ì¶œëœ ìµœì  ì‹œê°„ì°¨ (ì˜ˆì‹œ)

def prepare_data():
    """AirQualityì™€ í™”ë ¥ë°œì „ ë°ì´í„°ë¥¼ Pandasë¡œ ë¡œë“œ ë° í†µí•©í•©ë‹ˆë‹¤."""
    
    print("=== 1. Air Quality ë°ì´í„° ë¡œë“œ (ì „êµ­ ì›”í‰ê· ) ===")
    # Air Quality ë°ì´í„° ë¡œë“œ (ì´ë¯¸ ì „êµ­ ì›”í‰ê· ì´ ê³„ì‚°ë˜ì—ˆë‹¤ê³  ê°€ì •)
    # Sparkì—ì„œ ìƒì„± ì‹œ 'year', 'month', 'national_avg_PM10' ë“±ì„ í¬í•¨
    df_air = pd.read_csv(AIR_QUALITY_CSV)
    
    # Air Quality ë°ì´í„°ì˜ yearì™€ monthë¥¼ Integerë¡œ ë³€í™˜ (í•„ìˆ˜)
    df_air['year'] = df_air['year'].astype(int)
    df_air['month'] = df_air['month'].astype(int)
    
    
    print("=== 2. í™”ë ¥ë°œì „ ë°ì´í„° ë¡œë“œ ë° Unpivot (Wide -> Long) ===")
    df_power_wide = pd.read_csv(POWER_DATA_CSV)
    
    # ì»¬ëŸ¼ ì •ë¦¬: ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ 'month'ë¡œ ì„¤ì •
    df_power_wide.rename(columns={df_power_wide.columns[0]: 'month'}, inplace=True)
    
    # ì½¤ë§ˆ ì œê±° ë° ìˆ«ì ë³€í™˜
    for col_name in df_power_wide.columns[1:]:
        df_power_wide[col_name] = df_power_wide[col_name].astype(str).str.replace(',', '').astype(float)
    
    # Wide Formatì„ Long Formatìœ¼ë¡œ ë³€í™˜ (Melt/Unpivot)
    df_power_long = df_power_wide.melt(
        id_vars=['month'], 
        var_name='year', 
        value_name='Power_GWh'
    )
    
    # Year ì»¬ëŸ¼ì„ Integerë¡œ ë³€í™˜
    df_power_long['year'] = df_power_long['year'].astype(int)
    
    
    print("=== 3. ìµœì¢… í†µí•© (Merge) ===")
    # Air Qualityì™€ Power ë°ì´í„°ë¥¼ yearì™€ month í‚¤ë¡œ ë³‘í•©
    df_merged = pd.merge(df_air, df_power_long, on=['year', 'month'], how='inner')
    
    # Date ì¸ë±ìŠ¤ ìƒì„±
    df_merged['Date'] = pd.to_datetime(df_merged['year'].astype(str) + '-' + df_merged['month'].astype(str) + '-01')
    df_merged.set_index('Date', inplace=True)
    df_merged.sort_index(inplace=True)
    
    # ë¶„ì„ì— í•„ìš”í•œ ìµœì¢… ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
    return df_merged

def analyze_and_regress(df):
    """ìƒê´€ê´€ê³„ ë¶„ì„, ë³€ìˆ˜ ìƒì„± ë° ë‹¤ì¤‘ íšŒê·€ ëª¨ë¸ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    # 4. ë¶„ì„ ëŒ€ìƒ ì»¬ëŸ¼ ì„¤ì •
    analysis_cols = [c for c in df.columns if c.startswith('national_avg_') or c == 'Power_GWh']
    df_analysis = df[analysis_cols].astype(float)

    # 5. ìƒê´€ê´€ê³„ ë¶„ì„ (Pearson Correlation)
    print("\n=== 4. ìƒê´€ê´€ê³„ ë¶„ì„ (Pearson) ===")
    corr_matrix = df_analysis.corr(method='pearson')
    print("ë°œì „ëŸ‰ vs ì˜¤ì—¼ë¬¼ì§ˆ ìƒê´€ê³„ìˆ˜:\n", corr_matrix['Power_GWh'].sort_values(ascending=False))
    
    # íˆíŠ¸ë§µ ì‹œê°í™”
    plt.figure(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', 
                cbar_kws={'label': 'í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜'})
    plt.title('ì „êµ­ ë°œì „ëŸ‰ê³¼ ëŒ€ê¸°ì§ˆ ê°„ì˜ ìƒê´€ê´€ê³„')
    plt.tight_layout()
    plt.savefig(OUTPUT_LOCAL_HEATMAP)
    print(f"-> íˆíŠ¸ë§µ ì €ì¥ ì™„ë£Œ: {OUTPUT_LOCAL_HEATMAP}")
    
    
    # 6. ë‹¤ì¤‘ íšŒê·€ ëª¨ë¸ë§ (Multiple Regression)
    print("\n=== 5. ë‹¤ì¤‘ íšŒê·€ ëª¨ë¸ ì„¤ì • ë° ì í•© ===")
    
    # --- í•µì‹¬ Lag ë³€ìˆ˜ ìƒì„± ---
    df['Power_GWh_Lag1'] = df['Power_GWh'].shift(OPTIMAL_LAG)
    
    # --- í†µì œ ë³€ìˆ˜ ìƒì„± ---
    # ê³„ì ˆì„± í†µì œë¥¼ ìœ„í•œ ì›”(Month) ë”ë¯¸ ë³€ìˆ˜ ìƒì„±
    month_dummies = pd.get_dummies(df['month'], prefix='Month', drop_first=True)
    df = pd.concat([df, month_dummies], axis=1)

    # ì¥ê¸° ì¶”ì„¸(Trend) ë³€ìˆ˜ ìƒì„±
    df['Trend'] = np.arange(len(df))
    
    # Laggingìœ¼ë¡œ ì¸í•´ ë°œìƒí•œ NaN í–‰ ë° ëª¨ë“  NaN í–‰ ì œê±°
    df_regress = df.dropna()

    # ì¢…ì† ë³€ìˆ˜ (Y): PM10
    Y = df_regress[TARGET_POLLUTANT]
    
    # ë…ë¦½ ë³€ìˆ˜ (X): Lagged Power, Trend, Month Dummies
    X_vars = ['Power_GWh_Lag1', 'Trend'] + [c for c in df_regress.columns if c.startswith('Month_')]
    
    X = df_regress[X_vars]
    X = sm.add_constant(X) # ì ˆí¸(Intercept) ì¶”ê°€

    # OLS (Ordinary Least Squares) ëª¨ë¸ ì í•©
    model = sm.OLS(Y, X).fit()

    # 7. ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
    print("\n=== 6. íšŒê·€ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ===")
    summary_text = model.summary().as_text()
    
    print(summary_text)

    with open(OUTPUT_LOCAL_SUMMARY, 'w', encoding='utf-8') as f:
        f.write(summary_text)
        
    print(f"\nâœ… ìµœì¢… ë¶„ì„ ì™„ë£Œ. ìš”ì•½ ê²°ê³¼ê°€ ë¡œì»¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {OUTPUT_LOCAL_SUMMARY}")

if __name__ == "__main__":
    # ë°ì´í„° ì¤€ë¹„ ì „ì œ: national_monthly_avg.csv íŒŒì¼ ìƒì„± í•„ìš”
    # ì´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì „ì— í•´ë‹¹ íŒŒì¼ì´ /data/training/ ê²½ë¡œì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    try:
        final_df = prepare_data()
        analyze_and_regress(final_df)
    except Exception as e:
        print(f"\nâŒ ìµœì¢… ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        print("ğŸ’¡ [AirQuality CSV íŒŒì¼ëª… í™•ì¸ í•„ìš”] ë¡œì»¬ ê²½ë¡œì™€ íŒŒì¼ëª…ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")